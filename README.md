# Art Gallery Recommender üé®
An AI-powered gallery recommendation system that curates art exhibitions based on user preferences, mood, time, and location.

> **Note:** This is a demonstration version of a production ML system. Some configurations and business logic have been simplified for public sharing.

---

## üì∏ Watch the walkthrough
[![Watch the walkthrough!](https://img.youtube.com/vi/ZFtNlTuYH44/hqdefault.jpg)](https://youtube.com/shorts/ZFtNlTuYH44?feature=share)

---

## üìö Table of Contents
- [Features](#-features)
- [Architecture](#-architecture)
- [Screenshots](#-screenshots)
- [Tech Stack](#-tech-stack)
- [Local Dependencies](#-local-dependencies)
- [Cloud Services](#-cloud-services)
- [Project Structure](#-project-structure)
- [Installation](#-installation)

---

## ‚ú® Features
- üéØ **Personalized Recommendations** ‚Äî Curated art exhibitions using Retrieval-Augmented Generation (RAG) + gpt-4o model.
- üìç **Smart Filters** ‚Äî Suggests galleries based on location, exhibition dates, your current mood, reason to visit and your available time.
- üó∫Ô∏è **Map Integration** ‚Äî Easily navigate to galleries with in-app Apple Maps integration.
- ‚ö° **Low Latency Backend** ‚Äî Powered by Google Cloud Run and Qdrant vector search to bring the best free art exhinitions for you within seconds!
- üóÇÔ∏è **Cached Reports** ‚Äî Avoids regenerating LLM output for faster performance.

---

## üèó Architecture
This system demonstrates a modern ML architecture with:
- **RAG Pipeline**: Retrieval-Augmented Generation for personalized recommendations
- **Vector Search**: Qdrant for semantic similarity matching
- **Microservices**: FastAPI with async processing
- **ML Ops**: ZenML pipelines for ETL and feature engineering
- **Monitoring**: Opik integration for LLM observability

![Architecture Diagram](github-media/artomo_architecture.gif)

---

## üìñ Key Features Demonstrated

**RAG Pipeline Architecture**
- Semantic search with Qdrant vector database
- LLM-powered recommendation generation
- Context-aware prompt engineering

**ML Operations**
- Automated ETL pipelines with ZenML
- Feature engineering for recommendation systems  
- Model monitoring and experiment tracking

**Microservices Design**
- FastAPI with async request handling
- Modular domain-driven architecture
- Cloud-native deployment patterns

---

## üõ† Tech Stack
| Layer        | Technology |
|--------------|------------|
| **Frontend** | SwiftUI (iOS) |
| **Backend**  | FastAPI, Google Cloud Run |
| **Database** | MongoDB, Qdrant |
| **AI Models**| OpenAI GPT,  vector search |
| **Infra**    | ZenML, Docker |
| **Monitor**  | CometML, Opik |

---

## Local Dependencies

| Component        | Version (min) | Notes                               |
|------------------|---------------|-------------------------------------|
| Python           | 3.11.x        | Use pyenv to manage versions        |
| Poetry           | 1.7+          | Dependency + virtualenv management  |
| Docker           | 24+           | Optional for local container runs   |
| Qdrant (local)   | 1.9+          | Run via Docker for vector store     |
| MongoDB (local)  | 6.0+          | If you use Mongo; else remove       |
| ZenML (local)    | 0.74.0        | More information on installation and usage here: https://docs.zenml.io |
---

## Cloud Services

| Service              | Provider  | Purpose                                   |
|----------------------|-----------|-------------------------------------------|
| Cloud Run            | GCP       | Host FastAPI inference service            |
| Cloud Tasks          | GCP       | Async job dispatch for per-exhibition gen |
| Firestore (Native)   | GCP       | Cache for exhibition reports              |
| Secret Manager       | GCP       | API keys & config                         |
| Artifact Registry    | GCP       | Container images                          |
| Qdrant (Managed/VM)  | Qdrant/GCP| Vector search (exhibitions)               |
| OpenAI API           | OpenAI    | LLM report generation                     |
| Comet/Opik (optional)| Comet/Opik| Experiment/run tracking                   |

---

## üóÇÔ∏è Project Structure

This project follows **Domain-Driven Design** and **Clean Architecture** principles:

```bash
.
‚îú‚îÄ‚îÄ configs/                    # Pipeline configurations and settings
‚îú‚îÄ‚îÄ gallery_recommender/        # Core application package
‚îÇ   ‚îú‚îÄ‚îÄ application/           # Application services and use cases
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ crawlers/         # Data extraction services
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ preprocessing/    # Data transformation pipeline
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ rag/             # Retrieval-Augmented Generation logic
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ networks/        # ML model integrations
‚îÇ   ‚îú‚îÄ‚îÄ domain/               # Business logic and entities
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ base/            # Base classes for data persistence
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ *.py             # Domain models and types
‚îÇ   ‚îú‚îÄ‚îÄ infrastructure/       # External service integrations
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ db/              # Database connectors (MongoDB, Qdrant)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ gcp/             # Cloud platform integrations  
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ *.py             # API and monitoring services
‚îÇ   ‚îî‚îÄ‚îÄ model/               # ML inference implementations
‚îú‚îÄ‚îÄ pipelines/               # ZenML pipeline definitions
‚îú‚îÄ‚îÄ steps/                   # ZenML pipeline components
‚îú‚îÄ‚îÄ tools/                   # CLI utilities and service entry points
‚îî‚îÄ‚îÄ DEMO_NOTICE.md          # Important information about this demo version
```

### Architecture Highlights

- **Domain Layer**: Pure business logic, framework-independent
- **Application Layer**: Use cases and application services  
- **Infrastructure Layer**: External integrations and persistence
- **Clean Dependencies**: Dependency inversion principle maintained

## ZenML Monitoring

This project uses ZenML to trigger and monitor the ETL and feature engineering pipelines
![ZenML Monitoring](github-media/zenml_monitoring.png)
---

## Opik (Comet.ml) Monitoring

This project also utilizes a monitoring platform called Opik (by Comet.ML) to monitor the prompts and also LLM outputs
![Opik Monitoring](github-media/opik_monitoring.png)

## üöÄ Installation

> **‚ö†Ô∏è Important:** This is a demonstration repository showcasing ML system architecture. Production configurations, API keys, and proprietary business logic have been abstracted for public sharing.

### Prerequisites
```bash
# Install dependencies using Poetry
poetry install

# Set up environment variables
cp .env.example .env
# Edit .env with your configuration
```

### Local Development
```bash
# Start local infrastructure
poetry run poe local-infrastructure-up

# Run the ML service
poetry run poe run-inference-ml-service

# Run data processing pipeline
poetry run poe run-digital-data-etl-demo
```

### Docker Setup
```bash
# Start with Docker Compose
docker-compose up -d
```

## ‚öôÔ∏è Configuration

Copy `.env.example` to `.env` and configure:

```bash
# OpenAI API (required for LLM features)
OPENAI_API_KEY=your_openai_key

# Database (MongoDB for metadata, Qdrant for vectors)
DATABASE_HOST=localhost
QDRANT_DATABASE_HOST=localhost

# Optional: Monitoring
COMET_API_KEY=your_comet_key
```

## üß™ Demo Mode

The system includes mock data and simplified configurations for demonstration:

```bash
# Run with demo data
poetry run poe run-demo-pipeline

# Test recommendation endpoint
poetry run poe call-rag-retrieval-module
```

## üèóÔ∏è Technical Architecture

### RAG (Retrieval-Augmented Generation) Pipeline
1. **Document Embedding**: Art exhibition data vectorized using sentence transformers
2. **Semantic Search**: Qdrant vector database for similarity matching
3. **Context Retrieval**: Relevant exhibitions retrieved based on user query
4. **LLM Generation**: OpenAI GPT models generate personalized recommendations
5. **Response Formatting**: Structured output with exhibition details and reasoning

### ML Operations Pipeline
- **Data Ingestion**: Automated crawling and data extraction
- **Feature Engineering**: Text preprocessing and embedding generation
- **Model Deployment**: FastAPI services with async processing
- **Monitoring**: Opik integration for LLM observability
- **Orchestration**: ZenML for reproducible ML workflows

## üö® Important Notice

**Please read [DEMO_NOTICE.md](./DEMO_NOTICE.md) for important information about this demonstration version.**

This repository showcases technical architecture and implementation patterns. Production-specific business logic, data sources, and configurations have been abstracted for public sharing.

## üìã Requirements

- Python 3.11+
- Poetry for dependency management  
- Docker (optional, for local services)
- OpenAI API key (for LLM functionality)
- MongoDB and Qdrant (local or cloud)

## ü§ù Contributing

This is a demonstration repository. For educational purposes, feel free to:
- Study the architecture and implementation patterns
- Use as reference for similar ML systems
- Adapt components for your own projects

## üìÑ License

MIT License - See LICENSE file for details.
